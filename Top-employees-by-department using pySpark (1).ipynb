{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ccc34-57e4-4605-b73f-0cfc3928f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = 'your_access_key'\n",
    "secret_key = 'your_secret_key'\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "\n",
    "# If you are using Auto Loader file notification mode to load files, provide the AWS Region ID.\n",
    "aws_region = \"us-east-1\"\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + aws_region + \".amazonaws.com\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DecimalType, StringType, DateType\n",
    "from pyspark.sql.functions import col, when, count\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"sample-project\").getOrCreate()\n",
    "\n",
    "# Define Schemas\n",
    "employees_schema = StructType([\n",
    "    StructField(\"EMPLOYEE_ID\", IntegerType(), True),\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"EMAIL\", StringType(), True),\n",
    "    StructField(\"PHONE_NUMBER\", StringType(), True),\n",
    "    StructField(\"HIRE_DATE\", DateType(), True),\n",
    "    StructField(\"JOB_ID\", StringType(), True),\n",
    "    StructField(\"SALARY\", IntegerType(), True),\n",
    "    StructField(\"COMMISSION_PCT\", DecimalType(5, 2), True),\n",
    "    StructField(\"MANAGER_ID\", IntegerType(), True),\n",
    "    StructField(\"DEPARTMENT_ID\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "departments_schema = StructType([\n",
    "    StructField(\"DEPARTMENT_ID\", IntegerType(), True),\n",
    "    StructField(\"DEPARTMENT_NAME\", StringType(), True),\n",
    "    StructField(\"MANAGER_ID\", IntegerType(), True),\n",
    "    StructField(\"LOCATION_ID\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "locations_schema = StructType([\n",
    "    StructField(\"LOCATION_ID\", IntegerType(), True),\n",
    "    StructField(\"STREET_ADDRESS\", StringType(), True),\n",
    "    StructField(\"POSTAL_CODE\", StringType(), True),\n",
    "    StructField(\"CITY\", StringType(), True),\n",
    "    StructField(\"STATE_PROVINCE\", StringType(), True),\n",
    "    StructField(\"COUNTRY_ID\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read data from S3\n",
    "employees_df = spark.read.schema(employees_schema).option(\"header\", \"true\").csv(\"s3://vijaysampleproject/employee.csv\")\n",
    "departments_df = spark.read.schema(departments_schema).option(\"header\", \"true\").csv(\"s3://vijaysampleproject/departments.csv\")\n",
    "locations_df = spark.read.schema(locations_schema).option(\"header\", \"true\").csv(\"s3://vijaysampleproject/locations.csv\")\n",
    "\n",
    "# Salary Range Column\n",
    "employees_df = employees_df.withColumn(\n",
    "    \"salary_range\",\n",
    "    when(col(\"SALARY\") > 16000, \"High_Salary\")\n",
    "    .when((col(\"SALARY\") > 8000) & (col(\"SALARY\") <= 16000), \"Medium_Salary\")\n",
    "    .otherwise(\"Low_Salary\")\n",
    ")\n",
    "\n",
    "# Optional: Department-wise count\n",
    "windowSpec = Window.partitionBy(\"MANAGER_ID\").orderBy(\"DEPARTMENT_ID\")\n",
    "employees_df = employees_df.withColumn(\"dep_grouped\", count(\"*\").over(windowSpec))\n",
    "\n",
    "# Register as Temp Views\n",
    "employees_df.createOrReplaceTempView(\"employee\")\n",
    "departments_df.createOrReplaceTempView(\"departments\")\n",
    "locations_df.createOrReplaceTempView(\"locations\")\n",
    "\n",
    "# Join Query\n",
    "Employees_details = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        e.EMPLOYEE_ID, e.FIRST_NAME, e.SALARY, \n",
    "        d.DEPARTMENT_ID, d.DEPARTMENT_NAME, \n",
    "        l.LOCATION_ID, l.STATE_PROVINCE\n",
    "    FROM employee e \n",
    "    INNER JOIN departments d ON e.MANAGER_ID = d.MANAGER_ID \n",
    "    INNER JOIN locations l ON d.LOCATION_ID = l.LOCATION_ID\n",
    "\"\"\")\n",
    "\n",
    "# Convert to Pandas for Plotting\n",
    "Employees_details_pd = Employees_details.toPandas()\n",
    "\n",
    "# Visualizing using Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Limiting to top 10 by salary\n",
    "top_employees = Employees_details_pd\n",
    "\n",
    "# Plotting\n",
    "plt.bar(top_employees['DEPARTMENT_NAME'], top_employees['SALARY'], color='grey')\n",
    "plt.xlabel('Department Name')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Top 10 Highest Paid Employees by Department')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
